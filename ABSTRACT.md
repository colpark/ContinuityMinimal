# Abstract

Neural network foundation models face a fundamental challenge: maintaining coherent representations under sparse, irregular observations—the same challenge biological brains solve effortlessly. We argue that György Buzsáki's theory of brain rhythms provides not merely inspiration but a **logical proof** that continuity-aware, multi-scale representations are necessary for robust sparse sensing. Buzsáki's work demonstrates that the hippocampus represents spatial trajectories through phase precession, wherein discrete neural spikes are embedded at systematically varying phases of continuous theta oscillations (4–10 Hz), effectively compressing seconds of real-world experience into ~125ms oscillation cycles. This mechanism is not metaphorically but literally an interpolation algorithm: the oscillation itself serves as the continuous function that connects sparse samples, enabling the brain to "fill the void" between discrete sensory events. Furthermore, cross-frequency coupling—where fast gamma oscillations (~30–90 Hz) nest within slower theta rhythms—creates a hierarchical multi-scale temporal structure that binds local details to global context. Critically, these internal sequences persist even without sensory input, demonstrating self-sustaining dynamics that predict rather than merely react. If Buzsáki's theory is correct, then brain-like robustness to sparse sensing requires representations that are: (1) continuous rather than discrete, (2) phase-aware rather than purely content-based, (3) multi-scale rather than single-resolution, and (4) self-sustaining rather than purely feedforward. We propose that foundation models achieving human-level robustness to sparse, irregular inputs must incorporate these properties—not as optional enhancements, but as architectural necessities derived from the same computational constraints the brain has already solved.
